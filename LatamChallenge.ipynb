{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNryZOwdDIrgy4QM6YL7tCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julianaldas/LatamChallenge/blob/main/LatamChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LATAM CHALLENGE**"
      ],
      "metadata": {
        "id": "F5ktAN9c8pG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "file_path = \"farmers-protest-tweets-2021-2-4.json\""
      ],
      "metadata": {
        "id": "rwntnyMG8fYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:** Fechas que m√°s tweets existen y sus respectivos usuarios\n",
        "\n",
        "Optimizaci√≥n de tiempo y de memoria"
      ],
      "metadata": {
        "id": "XuyXbfeF8okY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mejorar la velocidad, cargamos todos los datos de fecha y usuario de una vez. La funci√≥n se explica con comentarios y se mide el tiempo de ejecuci√≥n. Este enfoque puede ser m√°s lento que el optimizado para la memoria, pero podr√≠a ser √∫til para conjuntos de datos m√°s peque√±os y menos anidados.\n",
        "\n",
        "Para optimizar la memoria, optamos por analizar el archivo line by line, lo que consume considerablemente menos memoria que el otro enfoque. En este caso, tambi√©n resulta ser m√°s r√°pido, posiblemente debido al gran tama√±o del archivo analizado."
      ],
      "metadata": {
        "id": "_4cb7SD29aFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los tipos de datos List y Tuple de la biblioteca typing para las anotaciones de tipo.\n",
        "# Tambi√©n importamos la clase datetime de la biblioteca datetime para trabajar con fechas y horas.\n",
        "# Luego importamos el m√≥dulo json para trabajar con datos JSON y defaultdict de la biblioteca collections para crear diccionarios con valores predeterminados.\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "\n",
        "    # Primero se guardan los datos de fecha y username en una lista de lista, para luego poder contarlos acordemente.\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = [[json.loads(line)['date'].split('T')[0], json.loads(line)['user']['username']]  for line in f.readlines()]\n",
        "\n",
        "    # Se utiliza la clase Counter() junto con list comprehension para obtener las 10 fechas mas comunes de todos los tweets.\n",
        "    most_common_dates = Counter([d[0] for d in data]).most_common(10)\n",
        "\n",
        "    # Se de manera similar, se obtiene el usuario que mas tweeti√≥ para cada una de las fechas mas comunes.\n",
        "    most_common_users = [Counter([d[1] for d in data if d[0] == date[0]]).most_common(1)[0][0] for date in most_common_dates]\n",
        "\n",
        "    # Se utiliza zip para agrupar las dos listas obtenidas anteriormente, recordando pasar la fecha a formato datetime.date().\n",
        "    return list(zip([datetime.strptime(date[0], \"%Y-%m-%d\").date() for date in most_common_dates], most_common_users))\n",
        "    from q1_time import q1_time\n",
        "\n",
        "initial_time = time()\n",
        "result = q1_time(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - initial_time} \")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgVztnWOxFxG",
        "outputId": "19932e26-ad77-4e35-9055-0d27f54d4602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 12.088545322418213 \n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los tipos de datos List y Tuple de la biblioteca typing para las anotaciones de tipo.\n",
        "# Tambi√©n importamos la clase datetime de la biblioteca datetime para trabajar con fechas y horas.\n",
        "# Luego importamos el m√≥dulo json para trabajar con datos JSON y defaultdict de la biblioteca collections para crear diccionarios con valores predeterminados.\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Definimos una funci√≥n llamada q1_memory que toma la ruta del archivo como entrada y devuelve una lista de tuplas que contienen fechas y usuarios.\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    # Creamos un defaultdict anidado para almacenar el recuento de tweets por usuario y fecha.\n",
        "    dates_counter = defaultdict(lambda: defaultdict(int))\n",
        "    # Abrimos el archivo JSON en modo de lectura.\n",
        "    with open(file_path, 'r') as file:\n",
        "        # Iteramos l√≠nea por l√≠nea en el archivo.\n",
        "        for line in file:\n",
        "            # Cargamos cada l√≠nea como un objeto JSON.\n",
        "            tweet = json.loads(line)\n",
        "            # Extraemos la fecha del tweet y la convertimos al formato deseado.\n",
        "            tweet_date = tweet['date'].split('T')[0]\n",
        "            # Extraemos el nombre de usuario del tweet.\n",
        "            username = tweet['user']['username']\n",
        "            # Actualizamos el contador de tweets para este usuario en esta fecha.\n",
        "            dates_counter[tweet_date][username] += 1\n",
        "\n",
        "    # Ordenamos las fechas seg√∫n el n√∫mero total de tweets (usuarios √∫nicos) publicados ese d√≠a.\n",
        "    top_dates = sorted(dates_counter.keys(), key=lambda x: sum(dates_counter[x].values()), reverse=True)[:10]\n",
        "\n",
        "    # Obtenemos el usuario con m√°s tweets para cada una de las fechas principales.\n",
        "    top_users = [max(dates_counter[date], key=dates_counter[date].get) for date in top_dates]\n",
        "\n",
        "    # Convertimos las fechas de cadena a objetos datetime.date().\n",
        "    top_dates = [datetime.strptime(date_str, \"%Y-%m-%d\").date() for date_str in top_dates]\n",
        "\n",
        "    # Combinamos las fechas y los usuarios en una lista de tuplas y la devolvemos.\n",
        "    return list(zip(top_dates, top_users))\n",
        "\n",
        "# El siguiente c√≥digo llama a la funci√≥n q1_memory con un archivo especificado y muestra el resultado.\n",
        "initial_time = time()\n",
        "result = q1_memory(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - initial_time} \")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "30u56EqdFoYb",
        "outputId": "c20b72f2-e869-4cf2-d87b-f985450c22fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 6.525227069854736 \n",
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2:** Contador de emojis\n",
        "\n",
        "Optimizaci√≥n de tiempo y de memoria"
      ],
      "metadata": {
        "id": "lpFjZugj9szS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se us√≥ la librer√≠a emoji para analizar el contenido de todos los tweets y obtener todos los emojis presentes en una sola cadena. Sin embargo, este enfoque result√≥ m√°s lento que el an√°lisis l√≠nea por l√≠nea. Se propone continuar optimizando el tiempo mediante la compartimentalizaci√≥n y el uso de subprocesos.\n",
        "\n",
        "Posteriormente, se aplic√≥ la misma l√≥gica que en el enfoque de optimizaci√≥n de tiempo, pero analizando l√≠nea por l√≠nea en lugar de construir una cadena √∫nica con todos los datos."
      ],
      "metadata": {
        "id": "xyUgfhMA-BK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los tipos de datos List y Tuple de la biblioteca typing para las anotaciones de tipo.\n",
        "# Tambi√©n importamos el m√≥dulo json para trabajar con datos JSON, emoji_list de la biblioteca emoji para trabajar con emojis,\n",
        "# y Counter de la biblioteca collections para contar elementos.\n",
        "from typing import List, Tuple\n",
        "import json\n",
        "from emoji import emoji_list\n",
        "from collections import Counter\n",
        "\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    # Leemos todas las l√≠neas del archivo y almacenamos los contenidos de los tweets en una lista.\n",
        "    with open(file_path, 'r') as f:\n",
        "        tweet_contents = [json.loads(line)['content'] for line in f]\n",
        "\n",
        "    # Concatenamos todos los contenidos de los tweets en un solo string.\n",
        "    all_tweets_content = \"\".join(tweet_contents)\n",
        "\n",
        "    # Usando el m√©todo emoji_list, obtenemos todos los emojis presentes en el string.\n",
        "    emojis = [emoji['emoji'] for emoji in emoji_list(all_tweets_content)]\n",
        "\n",
        "    # Contamos los emojis y devolvemos los 10 m√°s utilizados.\n",
        "    return Counter(emojis).most_common(10)\n",
        "\n",
        "# El siguiente c√≥digo llama a la funci√≥n q2_time con un archivo especificado y muestra el resultado.\n",
        "initial_time = time()\n",
        "result = q2_time(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - initial_time} \")\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRrwSzviqeRY",
        "outputId": "d51a2003-83c0-451e-f4b3-cd97707b6065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 26.301026344299316 \n",
            "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los tipos de datos List y Tuple de la biblioteca typing para las anotaciones de tipo.\n",
        "from typing import List, Tuple\n",
        "import json\n",
        "from emoji import emoji_list\n",
        "from collections import Counter\n",
        "\n",
        "# Definimos una funci√≥n llamada q2_time que toma la ruta del archivo como entrada y devuelve una lista de tuplas que contienen emojis y su recuento.\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    # Primero, se obtienen todos los objetos de tweets de una vez.\n",
        "    with open(file_path, 'r') as f:\n",
        "        tweets = f.readlines()\n",
        "\n",
        "    # Luego se obtiene un gran string que contenga todos los contenidos de los tweets.\n",
        "    all_content = \"\"\n",
        "    for tweet in tweets:\n",
        "        all_content += json.loads(tweet)['content']\n",
        "\n",
        "    # Usando el m√©todo emoji_list, se analiza todo el string y se obtienen todos los emojis presentes.\n",
        "    emojis = [emoji['emoji'] for emoji in emoji_list(all_content)]\n",
        "\n",
        "    # Se cuentan los emojis y se devuelven los 10 m√°s utilizados.\n",
        "    top_emojis = Counter(emojis).most_common(10)\n",
        "    return top_emojis\n",
        "\n",
        "# El siguiente c√≥digo llama a la funci√≥n q2_time con un archivo especificado y muestra el resultado.\n",
        "initial_time = time()\n",
        "result = q2_time(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - initial_time} \")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YxSAqCdq_Md",
        "outputId": "451af3e3-fb52-4da2-a39a-4b825543f9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 24.528691053390503 \n",
            "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3:** Menciones\n",
        "\n",
        "Optimizaci√≥n de tiempo y de memoria"
      ],
      "metadata": {
        "id": "Uf8R5i6l-Yma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este problema, se emple√≥ una estrategia directa: iterar sobre cada l√≠nea del archivo JSON y extraer los usuarios mencionados en cada tweet. Utilizando list comprehension, se obtuvieron los nombres de usuario de manera eficiente. Una mejora potencial podr√≠a implicar modificar la estructura del archivo JSON para evitar la necesidad de acceder a niveles anidados de datos."
      ],
      "metadata": {
        "id": "6Zhl1_vb-o11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos los tipos de datos List y Tuple de la biblioteca typing para las anotaciones de tipo, y Counter de la biblioteca collections para contar elementos.\n",
        "from typing import List, Tuple\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Definimos una funci√≥n llamada q3_memory que toma la ruta del archivo como entrada y devuelve una lista de tuplas que contienen usernames y su recuento.\n",
        "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    # Creamos un diccionario para almacenar los usuarios mencionados y su recuento.\n",
        "    usuarios_recuento = {}\n",
        "\n",
        "    # Abrimos el archivo en modo de lectura.\n",
        "    with open(file_path, 'r') as archivo:\n",
        "        # Iteramos sobre cada l√≠nea del archivo.\n",
        "        for linea in archivo:\n",
        "            # Cargamos la l√≠nea como un objeto JSON.\n",
        "            datos = json.loads(linea)\n",
        "            # Obtenemos la lista de usuarios mencionados.\n",
        "            usuarios_mencionados = datos.get('mentionedUsers')\n",
        "            # Si hay usuarios mencionados, los procesamos.\n",
        "            if usuarios_mencionados:\n",
        "                # Iteramos sobre cada usuario mencionado.\n",
        "                for usuario in usuarios_mencionados:\n",
        "                    # Obtenemos el nombre de usuario.\n",
        "                    nombre_usuario = usuario.get('username')\n",
        "                    # Actualizamos el contador para este usuario.\n",
        "                    usuarios_recuento[nombre_usuario] = usuarios_recuento.get(nombre_usuario, 0) + 1\n",
        "\n",
        "    # Ordenamos el diccionario por el recuento de usuarios mencionados en orden descendente.\n",
        "    usuarios_ordenados = sorted(usuarios_recuento.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Devolvemos los 10 usuarios m√°s mencionados como una lista de tuplas.\n",
        "    return usuarios_ordenados[:10]\n",
        "\n",
        "# Llamamos a la funci√≥n q3_memory con el archivo especificado y mostramos el resultado.\n",
        "tiempo_inicial = time()\n",
        "resultado = q3_memory(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - tiempo_inicial} \")\n",
        "print(resultado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj4LDnPA0ZFS",
        "outputId": "bc1819ac-d2d9-4aba-cafb-65141cab3b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 7.43938136100769 \n",
            "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    # Lista para almacenar los usernames mencionados en los tweets\n",
        "    usernames = []\n",
        "\n",
        "    # Abrimos el archivo y leemos l√≠nea por l√≠nea\n",
        "    with open(file_path, 'r') as f:\n",
        "        # Cargamos cada l√≠nea como un objeto JSON y obtenemos la lista de mentionedUsers\n",
        "        for line in f:\n",
        "            # Convertimos la l√≠nea JSON a un diccionario\n",
        "            tweet_data = json.loads(line)\n",
        "            # Obtenemos la lista de mentionedUsers del tweet actual\n",
        "            mentioned_users = tweet_data.get('mentionedUsers')\n",
        "            # Si la lista no est√° vac√≠a (no es None), la procesamos\n",
        "            if mentioned_users:\n",
        "                # Iteramos sobre cada usuario en la lista y a√±adimos su username a la lista de usernames\n",
        "                for user in mentioned_users:\n",
        "                    usernames.append(user['username'])\n",
        "\n",
        "    # Contamos la frecuencia de cada username y devolvemos los 10 m√°s comunes\n",
        "    return Counter(usernames).most_common(10)\n",
        "\n",
        "# Llamamos a la funci√≥n q3_time con el archivo especificado y mostramos el resultado\n",
        "initial_time = time()\n",
        "result = q3_time(file_path=file_path)\n",
        "print(f\"Tiempo de ejecuci√≥n: {time() - initial_time} \")\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuZhcr0E1Mj4",
        "outputId": "047a2e9a-4d27-4567-ed5a-c046cce836be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecuci√≥n: 6.208816289901733 \n",
            "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL de destino\n",
        "url = \"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\"\n",
        "\n",
        "# Datos a enviar en el cuerpo del POST request\n",
        "data = {\n",
        "    \"name\": \"Esteban Almeida\",\n",
        "    \"mail\": \"hugoestebanalmeida@gmail.com.com\",\n",
        "    \"github_url\": \"https://github.com/Julianaldas/LatamChallenge\"\n",
        "}\n",
        "\n",
        "# Realizar el POST request\n",
        "response = requests.post(url, json=data)\n",
        "\n",
        "# Verificar el c√≥digo de estado de la respuesta\n",
        "if response.status_code == 200:\n",
        "    print(\"POST request enviado exitosamente.\")\n",
        "else:\n",
        "    print(\"Error al enviar el POST request. C√≥digo de estado:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "iuUmCAsqBe1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d25b501-6108-4ba8-a35f-9351b1169574"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POST request enviado exitosamente.\n"
          ]
        }
      ]
    }
  ]
}